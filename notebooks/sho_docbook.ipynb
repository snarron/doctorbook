{
 "metadata": {
  "name": "sho_docbook"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Get Chapter1.xml and read it into BeautifulSoup"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from bs4 import BeautifulSoup\n",
      "import pandas as pd\n",
      "import nltk\n",
      "import urllib2\n",
      "\n",
      "ORIGINAL_DIRECTORY = '/Users/shoheinarron/Desktop/'\n",
      "PATH = 'Chapter1.xml'\n",
      "soup = BeautifulSoup(open(ORIGINAL_DIRECTORY+PATH, 'rt').read())\n",
      "\n",
      "#pre_soup = open(ORIGINAL_DIRECTORY+PATH, 'rt').read()\n",
      "#type(pre_soup)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Check which tags are in the soup"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#book_tags = set([tag.name for tag in soup.findAll(True)])\n",
      "#print(book_tags)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 45
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Get tags and terms and construct a Pandas DataFrame"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "\n",
      "list_for_df = []\n",
      "tags = ['keyword','author','indexterm','orgname','personname','phrase']\n",
      "for tag in tags:\n",
      "    for i in soup.findAll(tag):\n",
      "        if i.string == None:\n",
      "            list_for_df.append({ 'term':\" \".join([ child for child in i.stripped_strings ]), \\\n",
      "                                'tag': tag })\n",
      "        else:\n",
      "            list_for_df.append({ 'term': re.sub('  +','',str(i.string)), 'tag': tag })\n",
      "        \n",
      "df = pd.DataFrame(list_for_df)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#df[:50]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# split strings for further cleaning\n",
      "x = [string for string in soup.stripped_strings]\n",
      "proper_list = []\n",
      "for i in x:\n",
      "    for q in i.split():\n",
      "        if q[:3] != '\\u':\n",
      "            proper_list.append(q)\n",
      "proper_list = ' '.join(proper_list)\n",
      "#print proper_list\n",
      "\n",
      "# split up cleaned list for a cleaner split\n",
      "broken_list = proper_list.split(' ')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tagged_sentence = nltk.pos_tag(broken_list)\n",
      "#print tagged_sentence"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pos_list = ['NN', 'NNP', 'NNS', 'NNPS']\n",
      "nouns = [item[0] for item in tagged_sentence if (item[1] in pos_list)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#pos = ['NNPS']\n",
      "from collections import Counter\n",
      "from itertools import islice\n",
      "\n",
      "\n",
      "term_list = []\n",
      "\n",
      "chain = []\n",
      "for item in islice(tagged_sentence,None):\n",
      "    if item[1] in pos_list:\n",
      "        chain.append(item)\n",
      "    else:\n",
      "        if len(chain) > 0:\n",
      "            term_list.append(\" \".join([item[0].encode(\"utf8\") for item in chain]))\n",
      "            chain = []\n",
      "\n",
      "#term_count = Counter(sorted(term_list))\n",
      "#count_threshold = 1\n",
      "#in_text_nltk = []\n",
      "#for term, count in term_count.iteritems():\n",
      "#    if count > count_threshold:\n",
      "#        in_text_nltk.append([term.encode(\"utf8\"), count])\n",
      "\n",
      "\n",
      "in_text_nltk_counter = Counter(term_list)\n",
      "\n",
      "#print [(i, term_count[i]) for i in term_count if term_count[i] > 3]\n",
      "#print term_list"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#in_text_nltk\n",
      "\n",
      "in_text_nltk_series = pd.Series([i[0] for i in in_text_nltk], index=[i[1] for i in in_text_nltk])\n",
      "#in_text_nltk_series"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Regex party!\n",
      "# Feel free to add, subtract, and edit patterns for better results.\n",
      "\n",
      "from collections import Counter\n",
      "\n",
      "i = 0\n",
      "in_text_regex = []\n",
      "while i < len(broken_list):\n",
      "    if (len(broken_list[i]) > 5) and ('_' not in broken_list[i]):\n",
      "        # pick up -ize or -ise, but not -wise\n",
      "        if (re.match(\"[A-z]+ize$\", broken_list[i]) or (re.match(\"[A-z]+ise$\", broken_list[i]) and (broken_list[i] != \"wise\"))):\n",
      "            pass\n",
      "            #in_text_regex.append(broken_list[i].lower())\n",
      "        # pick up -ity\n",
      "        elif (re.match(\"[A-z]+ity$\", broken_list[i])):\n",
      "            pass\n",
      "            #in_text_regex.append(broken_list[i].lower())\n",
      "        # pick up two or more words with capital letters at the beginning of each word.\n",
      "        elif (re.match(\"^[A-Z][A-Za-z]+$\", broken_list[i])) and (re.match(\"^[A-Z][a-z]+$\", broken_list[i+1])) and i+1 < len(broken_list):\n",
      "            # pick up three\n",
      "            if (re.match(\"^[A-Z][A-Za-z]+$\", broken_list[i+2])) and i+2 < len(broken_list):\n",
      "                in_text_regex.append(broken_list[i] + ' ' + broken_list[i+1] + ' ' + broken_list[i+2])\n",
      "            # pick up two\n",
      "            else:\n",
      "                in_text_regex.append(broken_list[i] + ' ' + broken_list[i+1])\n",
      "        else:\n",
      "            pass\n",
      "        i += 1\n",
      "    else:\n",
      "        i += 1\n",
      "\n",
      "in_text_regex_counter = Counter(in_text_regex)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Check to see in_text_list_series is working\n",
      "#i = 0\n",
      "#while i < len(in_text_regex_counter):\n",
      "#    print in_text_regex_counter[i:i+50]\n",
      "#    i += 50\n",
      "#print in_text_list_series[:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Add extracted terms into a DataFrame"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "regex_df = pd.DataFrame({\"category\":'raw', \"term\":[i for i in in_text_regex_counter], 'count':[in_text_regex_counter[i] for i in in_text_regex_counter]})\n",
      "nltk_df = pd.DataFrame({\"category\":'raw', \"term\":[i for i in in_text_nltk_counter], 'count':[in_text_nltk_counter[i] for i in in_text_nltk_counter]})\n",
      "#nltk_df[:50], regex_df[:50]\n",
      "\n",
      "threshold = 1\n",
      "\n",
      "raw_df = nltk_df.append(regex_df)\n",
      "raw_df[:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Int64Index: 2613 entries, 0 to 93\n",
        "Data columns:\n",
        "category    2613  non-null values\n",
        "count       2613  non-null values\n",
        "term        2613  non-null values\n",
        "dtypes: int64(1), object(2)"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Function to query DBPedia to find a term's wikipedia url (not complete)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from urllib2 import urlopen\n",
      "\n",
      "query = 'http://lookup.dbpedia.org/api/search.asmx/PrefixSearch?MaxHits=5&QueryString='\n",
      "term = 'metadata'\n",
      "\n",
      "def check_dbpedia(query):\n",
      "    response = urlopen(query)\n",
      "    soup = BeautifulSoup(response.read())\n",
      "    for result in soup.find_all('result'):\n",
      "        for child in result.children:\n",
      "            try:\n",
      "                print(child.name,child.string)\n",
      "            except:\n",
      "                pass\n",
      "\n",
      "def try_dbpedia(query, term):\n",
      "    if urlopen(query+term):\n",
      "        #print term, True\n",
      "        return True\n",
      "    else:\n",
      "        #print term, False\n",
      "        return False\n",
      "\n",
      "db_list = []\n",
      "for term in raw_df.term:\n",
      "    db_list.append(try_dbpedia(query,term))\n",
      "#check_dbpedia(query+term)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "HTTPError",
       "evalue": "HTTP Error 400: Bad Request",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-44-759b657ef3a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mdb_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mterm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mdb_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtry_dbpedia\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;31m#check_dbpedia(query+term)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-44-759b657ef3a8>\u001b[0m in \u001b[0;36mtry_dbpedia\u001b[0;34m(query, term)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtry_dbpedia\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;31m#print term, True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Library/Frameworks/EPD64.framework/Versions/7.3/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout)\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_opener\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0m_opener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Library/Frameworks/EPD64.framework/Versions/7.3/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Library/Frameworks/EPD64.framework/Versions/7.3/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             response = self.parent.error(\n\u001b[0;32m--> 519\u001b[0;31m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Library/Frameworks/EPD64.framework/Versions/7.3/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Library/Frameworks/EPD64.framework/Versions/7.3/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    376\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Library/Frameworks/EPD64.framework/Versions/7.3/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_full_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 400: Bad Request"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Use .apply(check_dpedia) to run function across all terms"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}